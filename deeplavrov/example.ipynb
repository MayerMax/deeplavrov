{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "root_folders = ['..', '../..', './']\n",
    "root_folders = [os.path.abspath(os.path.join(x)) for x in root_folders]\n",
    "for path in root_folders:\n",
    "    if path not in sys.path:\n",
    "        sys.path.append(path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from deeplavrov.models.wordlevel import AttentionRNNTranslator\n",
    "from deeplavrov.vocabulary.vocabulary import Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# клетка для того, чтобы создать файлы в нужном формате\n",
    "\n",
    "def make_pairs_from_anki(path, num_examples=None):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "        if num_examples:\n",
    "            pairs = [x.split('\\t') for x in data[:min(len(data), num_examples)]]\n",
    "        else:\n",
    "            pairs = [x.split('\\t') for x in data]\n",
    "      \n",
    "    return [x[0].strip() for x in pairs], [x[1].strip() for x in pairs]\n",
    "\n",
    "path = os.path.join('rus-eng', 'rus.txt')\n",
    "num_examples = 30000\n",
    "input_lang, target_lang = make_pairs_from_anki(path, num_examples)\n",
    "\n",
    "with open('rus-eng/eng_anki_30000.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(input_lang))\n",
    "    \n",
    "with open('rus-eng/ru_anki_30000.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(target_lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = AttentionRNNTranslator(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocab took 2.0325536727905273 second(s)\n",
      "Building vocab took 2.0674877166748047 second(s)\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Epoch 1 Batch 0 Loss 2.1591\n",
      "Epoch 1 Batch 100 Loss 1.5410\n",
      "Epoch 1 Batch 200 Loss 1.7488\n",
      "Epoch 1 Batch 300 Loss 1.6534\n",
      "Epoch 1 Batch 400 Loss 1.8332\n",
      "Epoch 1 Loss 1.5573\n",
      "Time taken for 1 epoch 119.62601590156555 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.9722\n",
      "Epoch 2 Batch 100 Loss 1.2317\n",
      "Epoch 2 Batch 200 Loss 1.4457\n",
      "Epoch 2 Batch 300 Loss 1.3814\n",
      "Epoch 2 Batch 400 Loss 1.4404\n",
      "Epoch 2 Loss 1.2700\n",
      "Time taken for 1 epoch 121.04510569572449 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.9213\n",
      "Epoch 3 Batch 100 Loss 1.0486\n",
      "Epoch 3 Batch 200 Loss 1.2784\n",
      "Epoch 3 Batch 300 Loss 1.1941\n",
      "Epoch 3 Batch 400 Loss 1.1910\n",
      "Epoch 3 Loss 1.0838\n",
      "Time taken for 1 epoch 118.39483976364136 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.9167\n",
      "Epoch 4 Batch 100 Loss 0.8686\n",
      "Epoch 4 Batch 200 Loss 1.0481\n",
      "Epoch 4 Batch 300 Loss 0.9760\n",
      "Epoch 4 Batch 400 Loss 0.8011\n",
      "Epoch 4 Loss 0.8811\n",
      "Time taken for 1 epoch 121.16215467453003 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.7189\n",
      "Epoch 5 Batch 100 Loss 0.6236\n",
      "Epoch 5 Batch 200 Loss 0.7506\n",
      "Epoch 5 Batch 300 Loss 0.7431\n",
      "Epoch 5 Batch 400 Loss 0.5380\n",
      "Epoch 5 Loss 0.6662\n",
      "Time taken for 1 epoch 118.52189755439758 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.6048\n",
      "Epoch 6 Batch 100 Loss 0.4530\n",
      "Epoch 6 Batch 200 Loss 0.5643\n",
      "Epoch 6 Batch 300 Loss 0.4803\n",
      "Epoch 6 Batch 400 Loss 0.3645\n",
      "Epoch 6 Loss 0.4898\n",
      "Time taken for 1 epoch 121.18612122535706 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.5112\n",
      "Epoch 7 Batch 100 Loss 0.3073\n",
      "Epoch 7 Batch 200 Loss 0.3939\n",
      "Epoch 7 Batch 300 Loss 0.3538\n",
      "Epoch 7 Batch 400 Loss 0.2733\n",
      "Epoch 7 Loss 0.3661\n",
      "Time taken for 1 epoch 118.60299038887024 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.3920\n",
      "Epoch 8 Batch 100 Loss 0.2493\n",
      "Epoch 8 Batch 200 Loss 0.3701\n",
      "Epoch 8 Batch 300 Loss 0.3043\n",
      "Epoch 8 Batch 400 Loss 0.2836\n",
      "Epoch 8 Loss 0.2932\n",
      "Time taken for 1 epoch 121.1722161769867 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.3392\n",
      "Epoch 9 Batch 100 Loss 0.2464\n",
      "Epoch 9 Batch 200 Loss 0.3511\n",
      "Epoch 9 Batch 300 Loss 0.2491\n",
      "Epoch 9 Batch 400 Loss 0.2418\n",
      "Epoch 9 Loss 0.2478\n",
      "Time taken for 1 epoch 118.6207492351532 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.3115\n",
      "Epoch 10 Batch 100 Loss 0.1912\n",
      "Epoch 10 Batch 200 Loss 0.3072\n",
      "Epoch 10 Batch 300 Loss 0.2305\n",
      "Epoch 10 Batch 400 Loss 0.2591\n",
      "Epoch 10 Loss 0.2103\n",
      "Time taken for 1 epoch 120.93808722496033 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.2855\n",
      "Epoch 11 Batch 100 Loss 0.1726\n",
      "Epoch 11 Batch 200 Loss 0.2742\n",
      "Epoch 11 Batch 300 Loss 0.1789\n",
      "Epoch 11 Batch 400 Loss 0.2268\n",
      "Epoch 11 Loss 0.1872\n",
      "Time taken for 1 epoch 118.60256791114807 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.2665\n",
      "Epoch 12 Batch 100 Loss 0.1816\n",
      "Epoch 12 Batch 200 Loss 0.2292\n",
      "Epoch 12 Batch 300 Loss 0.1934\n",
      "Epoch 12 Batch 400 Loss 0.2166\n",
      "Epoch 12 Loss 0.1762\n",
      "Time taken for 1 epoch 121.09792709350586 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.2127\n",
      "Epoch 13 Batch 100 Loss 0.1846\n",
      "Epoch 13 Batch 200 Loss 0.2367\n",
      "Epoch 13 Batch 300 Loss 0.1964\n",
      "Epoch 13 Batch 400 Loss 0.2134\n",
      "Epoch 13 Loss 0.1625\n",
      "Time taken for 1 epoch 118.72522974014282 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.2481\n",
      "Epoch 14 Batch 100 Loss 0.1853\n",
      "Epoch 14 Batch 200 Loss 0.1806\n",
      "Epoch 14 Batch 300 Loss 0.1681\n",
      "Epoch 14 Batch 400 Loss 0.1798\n",
      "Epoch 14 Loss 0.1519\n",
      "Time taken for 1 epoch 120.81535339355469 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.2329\n",
      "Epoch 15 Batch 100 Loss 0.1734\n",
      "Epoch 15 Batch 200 Loss 0.2002\n",
      "Epoch 15 Batch 300 Loss 0.1654\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1b145ccb45f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtranslator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rus-eng/eng_anki_30000.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rus-eng/ru_anki_30000.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\coding\\deeplavrov\\deeplavrov\\models\\wordlevel.py\u001b[0m in \u001b[0;36mfit_from_file\u001b[1;34m(self, input_file, target_file, val_input_file, val_target_file)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m                 \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\coding\\deeplavrov\\deeplavrov\\models\\wordlevel.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self, inp, targ, enc_hidden)\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_StridedSliceGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    274\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ellipsis_mask\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"new_axis_mask\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m       shrink_axis_mask=op.get_attr(\"shrink_axis_mask\")), None, None, None\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice_grad\u001b[1;34m(shape, begin, end, strides, dy, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m   9510\u001b[0m         \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"begin_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end_mask\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9511\u001b[0m         \u001b[0mend_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ellipsis_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"new_axis_mask\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9512\u001b[1;33m         new_axis_mask, \"shrink_axis_mask\", shrink_axis_mask)\n\u001b[0m\u001b[0;32m   9513\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9514\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "translator.fit_from_file(input_file='rus-eng/eng_anki_30000.txt', target_file='rus-eng/ru_anki_30000.txt', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'я вижу .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.translate('I see.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'том был в тюрьме .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.translate('Tom was in jail.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'он исполнил свой долг .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.translate('He did his duty.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
